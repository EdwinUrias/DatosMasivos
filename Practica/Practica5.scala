import org.apache.spark.sql.SparkSession
val spark = SparkSession.builder().getOrCreate()
val df = spark.read.option("header", "true").option("inferSchema","true")csv("Sales.csv")
df.printSchema()
df.groupBy("Person").mean().show()
df.groupBy("Person").count().show()
df.groupBy("Person").max().show()
df.groupBy("Person").min().show()
df.groupBy("Person").sum().show()
df.groupBy("Company").mean().show()
df.groupBy("Company").count().show()
df.groupBy("Company").max().show()
df.groupBy("Company").min().show()
df.groupBy("Company").sum().show()
df.groupBy($"Company" === "GOOG").mean().show()
df.groupBy($"Company" === "FB").mean().show()
df.groupBy($"Company" === "MSFT").mean().show()
df.groupBy($"Company" === "GOOG").min().show()
df.groupBy($"Company" === "GOOG").max().show()
df.select(countDistinct("Sales")).show()
df.select(sumDistinct("Sales")).show()
df.select(variance("Sales")).show()
df.select(stddev("Sales")).show()
df.select(collect_set("Sales")).show()